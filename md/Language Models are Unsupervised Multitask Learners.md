# Language Models are Unsupervised Multitask Learners

## Abstract

Natural language processing tasks, such as question answering, machine translation, reading comprehension, and summarization, are typically approached with supervised learning on taskspecific datasets. We demonstrate that language models begin to learn these tasks without any explicit supervision when trained on a new dataset of millions of webpages called WebText. When conditioned on a document plus questions, the answers generated by the language model reach 55 F1 on the CoQA dataset - matching or exceeding the performance of 3 out of 4 baseline systems without using the 127,000+ training examples. The capacity of the language model is essential to the success of zero-shot task transfer and increasing it improves performance in a log-linear fashion across tasks. Our largest model, GPT-2, is a 1.5B parameter Transformer that achieves state of the art results on 7 out of 8 tested language modeling datasets in a zero-shot setting but still underfits WebText. Samples from the model reflect these improvements and contain coherent paragraphs of text. These findings suggest a promising path towards building language processing systems which learn to perform tasks from their naturally occurring demonstrations.

自然语言处理任务，如问题回答、机器翻译、阅读理解和总结，通常是通过在特定任务数据集上的监督学习来完成的。我们证明了，当语言模型在一个叫做WebText的数百万网页的新数据集上训练时，可以在没有任何明确监督的情况下开始学习这些任务。当以文档和问题为条件时，语言模型生成的答案在CoQA数据集上达到55 F1—在不使用127,000+训练示例的情况下匹配或超过4个基线系统中的3个。语言模型的能力对于零起点任务转移的成功至关重要，提高它可以以对数线性的方式提高任务之间的性能。我们最大的模型，GPT-2，是一个1.5B的参数转换器，在零镜头设置下，在8个测试的语言建模数据集中，有7个获得了最先进的结果，但仍然不适合WebText。模型中的样本反映了这些改进，并包含了连贯的文本段落。这些发现为构建语言处理系统提供了一条有希望的道路，该系统可以从自然发生的演示中学习执行任务。

## 1. Introduction

Machine learning systems now excel (in expectation) at tasks they are trained for by using a combination of large datasets, high-capacity models, and supervised learning (Krizhevsky et al., 2012) (Sutskever et al., 2014) (Amodei et al., 2016). Yet these systems are brittle and sensitive to slight changes in the data distribution (Recht et al., 2018) and task specification (Kirkpatrick et al., 2017). Current systems are better characterized as narrow experts rather than competent generalists. We would like to move towards more general systems which can perform many tasks – eventually without the need to manually create and label a training dataset for each one.

机器学习系统现在通过使用大数据集、高容量模型和监督学习的组合，在它们训练的任务中表现出色(在预期中)(Krizhevsky et al.， 2012) (Sutskever et al.， 2014) (Amodei et al.， 2016)。然而，这些系统对于数据分布(Recht et al.， 2018)和任务规范(Kirkpatrick et al.， 2017)中的细微变化是脆弱和敏感的。当前的系统被更好地描述为狭隘的专家，而不是称职的通才。我们希望向能够执行许多任务的更通用的系统发展——最终不需要为每个任务手动创建和标记训练数据集。

The dominant approach to creating ML systems is to collect a dataset of training examples demonstrating correct behavior for a desired task, train a system to imitate these behaviors, and then test its performance on independent and identically distributed (IID) held-out examples. This has served well to make progress on narrow experts. But the often erratic behavior of captioning models (Lake et al., 2017), reading comprehension systems (Jia & Liang, 2017), and image classifiers (Alcorn et al., 2018) on the diversity and variety of possible inputs highlights some of the shortcomings of this approach.

创建ML系统的主要方法是收集一组训练示例，这些示例演示了所需任务的正确行为，训练系统模仿这些行为，然后在独立且同分布(IID)的保留示例上测试其性能。这有助于在狭隘的专家方面取得进展。但是，字幕模型(Lake等，2017)、阅读理解系统(Jia & Liang, 2017)和图像分类器(Alcorn等，2018)在可能输入的多样性和多样性上的不稳定行为，突显了这种方法的一些缺点。

Our suspicion is that the prevalence of single task training on single domain datasets is a major contributor to the lack of generalization observed in current systems. Progress towards robust systems with current architectures is likely to require training and measuring performance on a wide range of domains and tasks. Recently, several benchmarks have been proposed such as GLUE (Wang et al., 2018) and decaNLP (McCann et al., 2018) to begin studying this.

我们怀疑，在单个域数据集上流行的单一任务训练是当前系统缺乏泛化的主要原因。使用当前体系结构的健壮系统的进展可能需要在广泛的领域和任务上进行培训和测量性能。最近，一些基准被提出，如GLUE (Wang et al.， 2018)和decaNLP (McCann et al.， 2018)开始研究这个。

Multitask learning (Caruana, 1997) is a promising framework for improving general performance. However, multitask training in NLP is still nascent. Recent work reports modest performance improvements (Yogatama et al., 2019) and the two most ambitious efforts to date have trained on a total of 10 and 17 (dataset, objective) pairs respectively (McCann et al., 2018) (Bowman et al., 2018). From a meta-learning perspective, each (dataset, objective) pair is a single training example sampled from the distribution of datasets and objectives. Current ML systems need hundreds to thousands of examples to induce functions which generalize well. This suggests that multitask training many need just as many effective training pairs to realize its promise with current approaches. It will be very difficult to continue to scale the creation of datasets and the design of objectives to the degree that may be required to brute force our way there with current techniques. This motivates exploring additional setups for performing multitask learning.

多任务学习(Caruana, 1997)是一种很有前途的提高综合性能的框架。然而，多任务训练在NLP中还处于起步阶段。最近的工作报告显示了适度的性能改进(Yogatama et al.， 2019)和迄今为止最雄心勃勃的两项工作分别针对10对和17对(数据集，目标)(McCann et al.， 2018) (Bowman et al.， 2018)。从元学习的角度来看，每个(数据集、目标)对都是从数据集和目标的分布中采样的单个训练示例。目前的毫升系统需要数百至数千个例子来归纳归纳功能。这表明，多任务训练需要许多有效的训练对，以实现其承诺与目前的方法。要想继续扩大数据集的创建和目标的设计，达到用现有技术强行达到的程度，将是非常困难的。这激发了对执行多任务学习的额外设置的探索。

The current best performing systems on language tasks utilize a combination of pre-training and supervised finetuning. This approach has a long history with a trend towards more flexible forms of transfer. First, word vectors were learned and used as inputs to task-specific architectures (Mikolov et al., 2013) (Collobert et al., 2011), then the contextual representations of recurrent networks were transferred (Dai & Le, 2015) (Peters et al., 2018), and recent work suggests that task-specific architectures are no longer necessary and transferring many self-attention blocks is sufficient (Radford et al., 2018) (Devlin et al., 2018).

目前在语言任务方面表现最好的系统是结合了培训前的培训和监督下的微调。这一方法历史悠久，其趋势是更灵活的转让形式。首先,词作为输入向量学习和使用特定于任务的架构(Mikolov et al ., 2013) (Collobert et al ., 2011),然后网络转移复发的上下文表示(戴&勒,2015)(Peters等人,2018),和最近的研究表明,特定于任务架构不再是必要和转移许多self-attention块就足够了(雷德福et al ., 2018) (Devlin et al ., 2018)。

These methods still require supervised training in order to perform a task. When only minimal or no supervised data is available, another line of work has demonstrated the promise of language models to perform specific tasks, such as commonsense reasoning (Schwartz et al., 2017) and sentiment analysis (Radford et al., 2017).

为了完成一项任务，这些方法仍然需要监督训练。当只有极少的或没有监督数据可用时，另一个领域的研究表明，语言模型有望执行特定的任务，如常识推理(Schwartz et al.， 2017)和情感分析(Radford et al.， 2017)。

In this paper, we connect these two lines of work and continue the trend of more general methods of transfer. We demonstrate language models can perform down-stream tasks in a zero-shot setting – without any parameter or architecture modification. We demonstrate this approach shows potential by highlighting the ability of language models to perform a wide range of tasks in a zero-shot setting. We achieve promising, competitive, and state of the art results depending on the task.

在本文中，我们将这两种工作联系起来，并延续了更一般的转移方法的趋势。我们证明了语言模型可以在零起点设置下执行下游任务——不需要任何参数或架构修改。我们通过强调语言模型在零镜头设置下执行广泛任务的能力来展示这种方法的潜力。我们根据任务实现有希望的、有竞争力的和最先进的结果。

## 2. Approach

At the core of our approach is language modeling. Language modeling is usually framed as unsupervised distribution estimation from a set of examples $(x_1, x_2, ..., x_n)$ each composed of variable length sequences of symbols $(s_1, s_2, ..., s_n)$. Since language has a natural sequential ordering, it is common to factorize the joint probabilities over symbols as the product of conditional probabilities (Jelinek & Mercer, 1980) (Bengio et al., 2003):

$p(x)=\prod_{i=1}^n p(s_n|s_1,...,s_{n-1})$

我们方法的核心是语言建模。语言建模通常从一组示例$(x_1, x_2，…$(s_1, s_2，…s_n)美元。由于语言具有自然的顺序性，通常将符号上的联合概率因式分解为条件概率的乘积(Jelinek & Mercer, 1980) (Bengio et al.， 2003):

This approach allows for tractable sampling from and estimation of p(x) as well as any conditionals of the form $p(s_{n-k}, ..., s_n | s_1, ..., s_{n-k-1})$. In recent years, there have been significant improvements in the expressiveness of models that can compute these conditional probabilities, such as self-attention architectures like the Transformer (Vaswani
et al., 2017).

这种方法允许对p(x)进行可处理的抽样和估计，以及$p(s_{n-k}, ..., s_n | s_1, ..., s_{n-k-1})$。近年来，可以计算这些条件概率的模型的表达性有了显著的改进，例如Transformer这样的自我关注架构(Vaswani et al.， 2017)。

Learning to perform a single task can be expressed in a probabilistic framework as estimating a conditional distribution $p(output|input)$. Since a general system should be able to perform many different tasks, even for the same input, it should condition not only on the input but also on the task to be performed. That is, it should model $p(output| input,task)$. This has been variously formalized in multitask and meta-learning settings. Task conditioning is often implemented at an architectural level, such as the task specific encoders and decoders in (Kaiser et al., 2017) or at an algorithmic level such as the inner and outer loop optimization framework of MAML (Finn et al., 2017). But as exemplified in McCann et al. (2018), language provides a flexible way to specify tasks, inputs, and outputs all as a sequence of symbols. For example, a translation training example can be written as the sequence (translate to french, english text, french text). Likewise, a reading comprehension training example can be written as (answer the question, document, question, answer). McCann et al. (2018) demonstrated it was possible to train a single model, the MQAN, to infer and perform many different tasks on examples with this type of format.

学习执行单个任务可以在概率框架中表示为估计条件分布$p(输出|输入)$。由于一个通用系统应该能够执行许多不同的任务，即使对于相同的输入，它不仅应该对输入设置条件，还应该对要执行的任务设置条件。也就是说，它应该建模$p(输出|输入，任务)$。这在多任务和元学习环境中得到了不同程度的形式化。任务调节通常在架构级实现，例如任务特定的编码器和解码器(Kaiser et al.， 2017)，或者在算法级实现，例如MAML的内环和外环优化框架(Finn et al.， 2017)。但如McCann等人(2018)所示，语言提供了一种灵活的方式来指定任务、输入和输出，所有这些都是作为符号序列。例如，可以将翻译训练示例编写为序列(翻译成法语、英语文本、法语文本)。同样，一个阅读理解训练的例子可以写成(回答问题、文档、问题、答案)。McCann等人(2018)证明，可以训练单一模型MQAN，以这种格式在示例上推断和执行许多不同的任务。

Language modeling is also able to, in principle, learn the tasks of McCann et al. (2018) without the need for explicit supervision of which symbols are the outputs to be predicted. Since the supervised objective is the the same as the unsupervised objective but only evaluated on a subset of the sequence, the global minimum of the unsupervised objective is also the global minimum of the supervised objective. In this slightly toy setting, the concerns with density estimation as a principled training objective discussed in (Sutskever et al., 2015) are side stepped. The problem instead becomes whether we are able to, in practice, optimize the unsupervised
objective to convergence. Preliminary experiments confirmed that sufficiently large language models are able to perform multitask learning in this toy-ish setup but learning is much slower than in explicitly supervised approaches.

原则上，语言建模也能够学习McCann等人(2018)的任务，而不需要明确地监督哪些符号是要预测的输出。由于监督目标与无监督目标相同，但仅在序列的一个子集上求值，因此无监督目标的全局最小值也是有监督目标的全局最小值。在这个稍微有些玩具的设置中，(Sutskever et al.， 2015)中讨论的将密度估计作为原则性训练目标的关注点被搁置一边。相反，问题变成了我们能否在实践中优化无监督目标以使其收敛。初步实验证实，足够大的语言模型能够在这种玩具式的设置中执行多任务学习，但学习速度比显式监督方法慢得多。

While it is a large step from the well-posed setup described above to the messiness of “language in the wild”, Weston (2016) argues, in the context of dialog, for the need to develop systems capable of learning from natural language directly and demonstrated a proof of concept – learning a QA task without a reward signal by using forward prediction of a teacher’s outputs. While dialog is an attractive approach, we worry it is overly restrictive. The internet contains a vast amount of information that is passively available without the need for interactive communication. Our speculation is
that a language model with sufficient capacity will begin to learn to infer and perform the tasks demonstrated in natural language sequences in order to better predict them, regardless of their method of procurement. If a language model is able to do this it will be, in effect, performing unsupervised multitask learning. We test whether this is the case by analyzing the performance of language models in a zero-shot setting on a wide variety of tasks.

虽然是一个大的步骤的适定的设置上面描述的混乱在野外“语言”,韦斯顿(2016)认为,在对话框中,需要开发系统能够直接从自然语言的学习,并演示了一个概念验证,学习一个QA任务没有奖励的信号通过使用向前预测老师的输出。虽然对话是一种有吸引力的方法，但我们担心它过于严格。互联网包含了大量的信息，人们可以被动地获取这些信息，而不需要进行互动交流。我们推测，一个具有足够能力的语言模型将开始学习推断和执行自然语言序列中所演示的任务，以便更好地预测它们，而不管它们的获取方法如何。如果一个语言模型能够做到这一点，那么它实际上就是在执行无监督的多任务学习。我们通过分析语言模型在各种任务上的零距离设置的性能来测试是否存在这种情况。

## 2.1. Training Dataset

Most prior work trained language models on a single domain of text, such as news articles (Jozefowicz et al., 2016), Wikipedia (Merity et al., 2016), or fiction books (Kiros et al., 2015). Our approach motivates building as large and diverse a dataset as possible in order to collect natural language demonstrations of tasks in as varied of domains and contexts as possible.

之前的大多数工作都是在单一文本领域训练语言模型，如新闻文章(Jozefowicz等人，2016)、维基百科(Merity等人，2016)或小说书籍(Kiros等人，2015)。我们的方法鼓励构建尽可能大和多样化的数据集，以收集在尽可能多的领域和环境中任务的自然语言演示。

A promising source of diverse and nearly unlimited text is web scrapes such as Common Crawl. While these archives are many orders of magnitude larger than current language modeling datasets, they have significant data quality issues. Trinh & Le (2018) used Common Crawl in their work on commonsense reasoning but noted a large amount of documents “whose content are mostly unintelligible”. We observed similar data issues in our initial experiments with Common Crawl. Trinh & Le (2018)’s best results were achieved using a small subsample of Common Crawl which included only documents most similar to their target dataset, the Winograd Schema Challenge. While this is a pragmatic approach to improve performance on a specific task, we
want to avoid making assumptions about the tasks to be performed ahead of time.

一个有前途的来源，多样化和几乎无限的文本是网页刮擦，如常见的爬行。虽然这些归档文件比当前的语言建模数据集要大很多个数量级，但它们存在严重的数据质量问题。Trinh & Le(2018)在他们关于常识推理的工作中使用了普通的爬行，但是注意到大量的文档“其内容大多是难以理解的”。我们在最初的普通爬行实验中观察到类似的数据问题。Trinh和Le(2018)的最佳结果是通过使用一个小的常见爬行子样本实现的，该子样本只包含与目标数据集最相似的文档，即Winograd模式挑战。虽然这是一种提高特定任务性能的实用方法，但我们希望避免对将要提前执行的任务做出假设。

Instead, we created a new web scrape which emphasizes document quality. To do this we only scraped web pages which have been curated/filtered by humans. Manually filtering a full web scrape would be exceptionally expensive so as a starting point, we scraped all outbound links from Reddit, a social media platform, which received at least 3 karma. This can be thought of as a heuristic indicator for whether other users found the link interesting, educational, or just funny.

相反，我们创建了一个新的web刮，强调文档质量。为了做到这一点，我们只抓取那些由人类管理/过滤的网页。手动过滤一个完整的网页抓取会非常昂贵，所以作为一个起点，我们从社交媒体平台Reddit上抓取所有的出站链接，这个平台至少收到了3个karma。这可以被看作是其他用户是否觉得链接有趣、有教育意义或仅仅是有趣的启发式指示器。

The resulting dataset, WebText, contains the text subset of these 45 million links. To extract the text from HTML responses we use a combination of the Dragnet (Peters & Lecocq, 2013) and Newspaper1 content extractors. All results presented in this paper use a preliminary version of WebText which does not include links created after Dec 2017 and which after de-duplication and some heuristic based cleaning contains slightly over 8 million documents for a total of 40 GB of text. We removed all Wikipedia
documents from WebText since it is a common data source for other datasets and could complicate analysis due to over-lapping training data with test evaluation tasks.

得到的数据集WebText包含这4500万个链接的文本子集。为了从HTML响应中提取文本，我们结合使用了Dragnet (Peters & Lecocq, 2013)和Newspaper1内容提取器。本文中的所有结果都使用了WebText的初步版本，该版本不包括在2017年12月之后创建的链接，在重复删除和基于启发式清理之后，包含了总计40gb文本的800多万个文档。我们从WebText中删除了所有的Wikipedia文档，因为它是其他数据集的公共数据源，并且可能由于训练数据与测试评估任务重叠而使分析变得复杂。

## 2.2. Input Representation

A general language model (LM) should be able to compute the probability of (and also generate) any string. Current large scale LMs include pre-processing steps such as lowercasing, tokenization, and out-of-vocabulary tokens which restrict the space of model-able strings. While processing Unicode strings as a sequence of UTF-8 bytes elegantly fulfills this requirement as exemplified in work such as Gillick et al. (2015), current byte-level LMs are not competitive with word-level LMs on large scale datasets such as the One Billion Word Benchmark (Al-Rfou et al., 2018). We observed a similar performance gap in our own attempts to
train standard byte-level LMs on WebText.

通用语言模型(LM)应该能够计算(并生成)任何字符串的概率。当前的大型LMs包括预处理步骤，如小写、标记化和词汇表外标记，这些步骤限制了可建模字符串的空间。虽然将Unicode字符串处理为UTF-8字节序列很好地满足了这一要求，如Gillick等人(2015)的工作就证明了这一点，但当前的字节级LMs在大规模数据集(如十亿字基准测试)上无法与字级LMs竞争(al - rfou等人，2018)。我们在自己尝试在WebText上训练标准字节级LMs时也观察到了类似的性能差距。

Byte Pair Encoding (BPE) (Sennrich et al., 2015) is a practical middle ground between character and word level language modeling which effectively interpolates between word level inputs for frequent symbol sequences and character level inputs for infrequent symbol sequences. Despite its name, reference BPE implementations often operate on Unicode code points and not byte sequences. These implementations would require including the full space of Unicode symbols in order to model all Unicode strings. This would result in a base vocabulary of over 130,000 before any multi-symbol tokens are added. This is prohibitively large compared to the 32,000 to 64,000 token vocabularies often used with BPE. In contrast, a byte-level version of BPE only requires a base vocabulary of size 256. However, directly applying BPE to the byte sequence results in suboptimal merges due to BPE using a greedy frequency based heuristic for building the token vocabulary. We observed BPE including many versions of common words like dog since they occur in many variations such as dog. dog! dog? . This results in a sub-optimal allocation of limited vocabulary slots and model capacity. To avoid this, we prevent BPE from merging across character categories for any byte sequence. We add an exception for spaces which significantly improves the compression efficiency while adding only minimal fragmentation of words across multiple vocab tokens.

字节对编码(Byte Pair Encoding, BPE) (Sennrich et al.， 2015)是一种介于字符级和字级之间的实用中间地带的语言建模方法，它可以有效地插值频繁符号序列的字级输入和不频繁符号序列的字符级输入。尽管名为BPE，但引用BPE实现通常操作Unicode代码点，而不是字节序列。这些实现需要包含Unicode符号的完整空间，以便对所有Unicode字符串建模。这将导致在添加任何多符号标记之前基词汇表超过130,000。与通常与BPE一起使用的32,000到64,000个令牌词汇表相比，这实在是太大了。相比之下，字节级版本的BPE只需要256个基本词汇表。然而，直接将BPE应用于字节序列会导致次优合并，因为BPE使用基于贪婪频率的启发式方法来构建令牌词汇表。我们观察到BPE中包含了很多像dog这样的常用词，因为它们出现在很多变体中，比如dog。狗!狗吗?.这导致有限的词汇槽和模型容量的次优分配。为了避免这种情况，我们防止BPE跨字符类别合并任何字节序列。我们为空格添加了一个异常，它显著地提高了压缩效率，同时跨多个vocab标记只添加了最小的单词碎片。

This input representation allows us to combine the empirical benefits of word-level LMs with the generality of byte-level approaches. Since our approach can assign a probability to any Unicode string, this allows us to evaluate our LMs on any dataset regardless of pre-processing, tokenization, or vocab size.

这种输入表示允许我们将字级LMs的经验优势与字节级方法的通用性结合起来。由于我们的方法可以为任何Unicode字符串赋值一个概率，这允许我们在任何数据集上计算LMs，而不管预处理、记号化或vocab的大小。

### 2.3. Model

We use a Transformer (Vaswani et al., 2017) based architecture for our LMs. The model largely follows the details of the OpenAI GPT model (Radford et al., 2018) with a few modifications. Layer normalization (Ba et al., 2016)
was moved to the input of each sub-block, similar to a pre-activation residual network (He et al., 2016) and an additional layer normalization was added after the final selfattention block. A modified initialization which accounts for the accumulation on the residual path with model depth
is used. We scale the weights of residual layers at initialization
by a factor of $1/\sqrt{N}$ where N is the number of residual layers. The vocabulary is expanded to 50,257. We also increase the context size from 512 to 1024 tokens and a larger batchsize of 512 is used.

## 3. Experiments

We trained and benchmarked four LMs with approximately log-uniformly spaced sizes. The architectures are summarized in Table 2. The smallest model is equivalent to the original GPT, and the second smallest equivalent to the
largest model from BERT (Devlin et al., 2018). Our largest model, which we call GPT-2, has over an order of magnitude more parameters than GPT. The learning rate of each model was manually tuned for the best perplexity on a 5% held-out sample of WebText. All models still underfit Web-Text and held-out perplexity has as of yet improved given more training time.

我们对四个LMs进行了训练和基准测试，它们的大小大约是log均匀间隔的。架构总结在表2中。最小的模型相当于原始的GPT，第二小的模型相当于BERT (Devlin et al.， 2018)的最大模型。我们最大的模型，我们称之为GPT-2，它的参数比GPT多一个数量级。每个模型的学习率都是在5%的WebText样本上手动调整以获得最佳的perplexity。所有的模型仍然不适合网络文本和helout perplexity已经改善了给更多的训练时间。

### 3.1. Language Modeling

As an initial step towards zero-shot task transfer, we are interested in understanding how WebText LM’s perform at zero-shot domain transfer on the primary task they are trained for – language modeling. Since our model operates on a byte level and does not require lossy pre-processing
or tokenization, we can evaluate it on any language model benchmark. Results on language modeling datasets are commonly reported in a quantity which is a scaled or exponentiated version of the average negative log probability per canonical prediction unit - usually a character, a byte, or
a word. We evaluate the same quantity by computing the log-probability of a dataset according to a WebText LM and dividing by the number of canonical units. For many of these datasets, WebText LMs would be tested significantly outof- distribution, having to predict aggressively standardized text, tokenization artifacts such as disconnected punctuation
and contractions, shuffled sentences, and even the string <UNK> which is extremely rare in WebText - occurring only 26 times in 40 billion bytes. We report our main results in Table 3 using invertible de-tokenizers which remove as many of these tokenization / pre-processing artifacts as possible. Since these de-tokenizers are invertible, we can still calculate the log probability of a dataset and they can be thought of as a simple form of domain adaptation. We observe gains of 2.5 to 5 perplexity for GPT-2 with these de-tokenizers.

作为迈向零镜头任务转移的第一步，我们有兴趣了解WebText LM如何在零镜头域转移的主要任务上执行他们被训练为非语言建模。由于我们的模型在字节级别上运行，不需要有损预处理或标记化，所以我们可以在任何语言模型基准上对其进行评估。语言建模数据集的结果通常以每规范预测单元(通常是一个字符、一个字节或一个单词)的平均负对数概率的比例或指数形式来报告。我们通过根据WebText LM计算数据集的日志概率，并除以规范单元的数量来评估相同的数量。对于许多这样的数据集，WebText LMs将被测试出显著的out - distribution，必须预测积极标准化的文本，标记化工件，如断开的标点和缩写，打乱的句子，甚至字符串，这在WebText中极为罕见，在400亿字节中仅出现26次。我们在表3中报告了使用可逆反令牌器的主要结果，该反令牌器删除了尽可能多的这些令牌化/预处理工件。由于这些解记号器是可逆的，我们仍然可以计算数据集的日志概率，它们可以被认为是一种简单的域适应形式。我们观察到使用这些解令器GPT-2获得2.5到5个perplexity。

WebText LMs transfer well across domains and datasets, improving the state of the art on 7 out of the 8 datasets in a zero-shot setting. Large improvements are noticed on small datasets such as Penn Treebank and WikiText-2 which have only 1 to 2 million training tokens. Large improvements are also noticed on datasets created to measure long-term
dependencies like LAMBADA (Paperno et al., 2016) and the Children’s Book Test (Hill et al., 2015). Our model is still significantly worse than prior work on the One Billion Word Benchmark (Chelba et al., 2013). This is likely due to a combination of it being both the largest dataset and having some of the most destructive pre-processing - 1BW’s sentence level shuffling removes all long-range structure.

WebText LMs可以很好地跨域和数据集传输，在一个零镜头设置中改进8个数据集中的7个数据集的状态。在小型的数据集中，如Penn Treebank和WikiText-2，只有100万到200万的训练令牌，可以看到很大的改进。在为测量长期依赖关系而创建的数据集(如LAMBADA (Paperno et al.， 2016)和儿童书籍测试(Hill et al.， 2015)上也发现了巨大的改进。我们的模型仍然比之前在十亿词基准上的工作要差很多(Chelba et al.， 2013)。这可能是由于它既是最大的数据集，又有一些最具破坏性的预处理——1BW的句子层次变换删除了所有的长程结构。

### 3.2. Children’s Book Test

The Children’s Book Test (CBT) (Hill et al., 2015) was created to examine the performance of LMs on different categories of words: named entities, nouns, verbs, and prepositions. Rather than reporting perplexity as an evaluation metric, CBT reports accuracy on an automatically constructed cloze test where the task is to predict which of 10 possible choices for an omitted word is correct. Following the LM approach introduced in the original paper, we compute the probability of each choice and the rest of the sentence conditioned on this choice according to the LM, and predict the one with the highest probability. As seen in Figure 2 performance steadily improves as model size is increased and closes the majority of the gap to human performance on this test. Data overlap analysis showed one of the CBT test set books, The Jungle Book by Rudyard Kipling, is in WebText, so we report results on the validation set which has no significant overlap. GPT-2 achieves new state of the art results of 93.3% on common nouns and 89.1% on named entities. A de-tokenizer was applied to remove PTB style tokenization artifacts from CBT.

儿童书籍测试(CBT) (Hill et al.， 2015)是为了检查LMs在不同类别的单词上的表现:命名实体、名词、动词和介词。CBT并没有将复杂程度作为一个评估指标，而是在一个自动构建的完形填空测试中报告准确性，该测试的任务是预测一个遗漏的单词在10个选项中哪个选项是正确的。按照原文介绍的LM方法，我们根据LM计算出每个选择的概率以及以此为条件的句子其余部分，并预测出概率最高的一个。如图2所示，随着模型大小的增加，性能稳步提高，并消除了在此测试中与人类性能的大部分差距。数据重叠分析显示，其中一个CBT测试集集，鲁德亚德·吉卜林的《奇幻森林》，是在WebText中，所以我们报告的验证集的结果没有明显的重叠。GPT-2在常见名词上获得了93.3%的最新成果，在命名实体上获得了89.1%的最新成果。在CBT中应用去标记器去除PTB风格的标记伪影。



