# Language Models are Unsupervised Multitask Learners

## Abstract

Natural language processing tasks, such as question answering, machine translation, reading comprehension, and summarization, are typically approached with supervised learning on taskspecific datasets. We demonstrate that language models begin to learn these tasks without any explicit supervision when trained on a new dataset of millions of webpages called WebText. When conditioned on a document plus questions, the answers generated by the language model reach 55 F1 on the CoQA dataset - matching or exceeding the performance of 3 out of 4 baseline systems without using the 127,000+ training examples. The capacity of the language model is essential to the success of zero-shot task transfer and increasing it improves performance in a log-linear fashion across tasks. Our largest model, GPT-2, is a 1.5B parameter Transformer that achieves state of the art results on 7 out of 8 tested language modeling datasets in a zero-shot setting but still underfits WebText. Samples from the model reflect these improvements and contain coherent paragraphs of text. These findings suggest a promising path towards building language processing systems which learn to perform tasks from their naturally occurring demonstrations.

自然语言处理任务，如问题回答、机器翻译、阅读理解和总结，通常是通过在特定任务数据集上的监督学习来完成的。我们证明了，当语言模型在一个叫做WebText的数百万网页的新数据集上训练时，可以在没有任何明确监督的情况下开始学习这些任务。当以文档和问题为条件时，语言模型生成的答案在CoQA数据集上达到55 F1—在不使用127,000+训练示例的情况下匹配或超过4个基线系统中的3个。语言模型的能力对于零起点任务转移的成功至关重要，提高它可以以对数线性的方式提高任务之间的性能。我们最大的模型，GPT-2，是一个1.5B的参数转换器，在零镜头设置下，在8个测试的语言建模数据集中，有7个获得了最先进的结果，但仍然不适合WebText。模型中的样本反映了这些改进，并包含了连贯的文本段落。这些发现为构建语言处理系统提供了一条有希望的道路，该系统可以从自然发生的演示中学习执行任务。

## 1. Introduction

Machine learning systems now excel (in expectation) at tasks they are trained for by using a combination of large datasets, high-capacity models, and supervised learning (Krizhevsky et al., 2012) (Sutskever et al., 2014) (Amodei et al., 2016). 
Yet these systems are brittle and sensitive to slight changes in the data distribution (Recht et al., 2018) and task specification (Kirkpatrick et al., 2017). Current systems are better characterized as narrow experts rather than competent generalists. We would like to move towards more general systems which can perform many tasks – eventually without the need to manually create and label a training dataset for each one.

1. Krizhevsky, A., Sutskever, I., and Hinton, G. E. Imagenet classification with deep convolutional neural networks. In Advances in neural information processing systems, pp. 1097–1105, 2012.
2. Sutskever, I., Vinyals, O., and Le, Q. V. Sequence to sequence learning with neural networks. In Advances in neural information processing systems, pp. 3104–3112, 2014.
3. Amodei, D., Ananthanarayanan, S., Anubhai, R., Bai, J., Battenberg, E., Case, C., Casper, J., Catanzaro, B., Cheng, Q., Chen, G., et al. Deep speech 2: End-to-end speech recognition in english and mandarin. In International Conference on Machine Learning, pp. 173–182, 2016.

4. Recht, B., Roelofs, R., Schmidt, L., and Shankar, V. Do cifar-10 classifiers generalize to cifar-10? arXiv preprint arXiv:1806.00451, 2018.
5. Finn, C., Abbeel, P., and Levine, S. Model-agnostic metalearning for fast adaptation of deep networks. arXiv preprint arXiv:1703.03400, 2017.

机器学习系统现在通过使用大数据集、高容量模型和监督学习的组合，在它们训练的任务中表现出色(在预期中)(Krizhevsky et al.， 2012) (Sutskever et al.， 2014) (Amodei et al.， 2016)。然而，这些系统对于数据分布(Recht et al.， 2018)和任务规范(Kirkpatrick et al.， 2017)中的细微变化是脆弱和敏感的。当前的系统被更好地描述为狭隘的专家，而不是称职的通才。我们希望向能够执行许多任务的更通用的系统发展——最终不需要为每个任务手动创建和标记训练数据集。

The dominant approach to creating ML systems is to collect a dataset of training examples demonstrating correct behavior for a desired task, train a system to imitate these behaviors, and then test its performance on independent and identically distributed (IID) held-out examples. This has served well to make progress on narrow experts. But the often erratic behavior of captioning models (Lake et al., 2017), reading comprehension systems (Jia & Liang, 2017), and image classifiers (Alcorn et al., 2018) on the diversity and variety of possible inputs highlights some of the shortcomings of this approach.

1. Lake, B. M., Ullman, T. D., Tenenbaum, J. B., and Gershman, S. J. Building machines that learn and think like people. Behavioral and Brain Sciences, 40, 2017.
2. Jia, R. and Liang, P. Adversarial examples for evaluating reading comprehension systems. arXiv preprint arXiv:1707.07328,
3. Alcorn, M. A., Li, Q., Gong, Z., Wang, C., Mai, L., Ku, W.-S., and Nguyen, A. Strike (with) a pose: Neural networks are easily fooled by strange poses of familiar objects. arXiv preprint arXiv:1811.11553, 2018.

创建ML系统的主要方法是收集一组训练示例，这些示例演示了所需任务的正确行为，训练系统模仿这些行为，然后在独立且同分布(IID)的保留示例上测试其性能。这有助于在狭隘的专家方面取得进展。但是，字幕模型(Lake等，2017)、阅读理解系统(Jia & Liang, 2017)和图像分类器(Alcorn等，2018)在可能输入的多样性和多样性上的不稳定行为，突显了这种方法的一些缺点。

Our suspicion is that the prevalence of single task training on single domain datasets is a major contributor to the lack of generalization observed in current systems. Progress towards robust systems with current architectures is likely to require training and measuring performance on a wide range of domains and tasks. Recently, several benchmarks have been proposed such as GLUE (Wang et al., 2018) and decaNLP (McCann et al., 2018) to begin studying this.

1. Wang, A., Singh, A., Michael, J., Hill, F., Levy, O., and Bowman, S. R. Glue: A multi-task benchmark and analysis platform for natural language understanding. arXiv preprint arXiv:1804.07461, 2018.
2. McCann, B., Keskar, N. S., Xiong, C., and Socher, R. The natural language decathlon: Multitask learning as question answering. arXiv preprint arXiv:1806.08730, 2018.

我们怀疑，在单个域数据集上流行的单一任务训练是当前系统缺乏泛化的主要原因。使用当前体系结构的健壮系统的进展可能需要在广泛的领域和任务上进行培训和测量性能。最近，一些基准被提出，如GLUE (Wang et al.， 2018)和decaNLP (McCann et al.， 2018)开始研究这个。

Multitask learning (Caruana, 1997) is a promising framework for improving general performance. However, multitask training in NLP is still nascent. Recent work reports modest performance improvements (Yogatama et al., 2019) and the two most ambitious efforts to date have trained on a total of 10 and 17 (dataset, objective) pairs respectively (McCann et al., 2018) (Bowman et al., 2018). From a meta-learning perspective, each (dataset, objective) pair is a single training example sampled from the distribution of datasets and objectives. Current ML systems need hundreds to thousands of examples to induce functions which generalize well. This suggests that multitask training many need just as many effective training pairs to realize its promise with current approaches. It will be very difficult to continue to scale the creation of datasets and the design of objectives to the degree that may be required to brute force our way there with current techniques. This motivates exploring additional setups for performing multitask learning.

1. Caruana, R. Multitask learning. Machine learning, 28(1):41–75,1997
2. Yogatama, D., d’Autume, C. d. M., Connor, J., Kocisky, T., Chrzanowski, M., Kong, L., Lazaridou, A., Ling, W., Yu, L., Dyer, C., et al. Learning and evaluating general linguistic intelligence. arXiv preprint arXiv:1901.11373, 2019.
3. McCann, B., Keskar, N. S., Xiong, C., and Socher, R. The natural language decathlon: Multitask learning as question answering. arXiv preprint arXiv:1806.08730, 2018.
4. Bowman, S. R., Pavlick, E., Grave, E., Van Durme, B., Wang, A., Hula, J., Xia, P., Pappagari, R., McCoy, R. T., Patel, R., et al. Looking for elmo’s friends: Sentence-level pretraining beyond language modeling. arXiv preprint arXiv:1812.10860, 2018.

多任务学习(Caruana, 1997)是一种很有前途的提高综合性能的框架。然而，多任务训练在NLP中还处于起步阶段。最近的工作报告显示了适度的性能改进(Yogatama et al.， 2019)和迄今为止最雄心勃勃的两项工作分别针对10对和17对(数据集，目标)(McCann et al.， 2018) (Bowman et al.， 2018)。从元学习的角度来看，每个(数据集、目标)对都是从数据集和目标的分布中采样的单个训练示例。目前的毫升系统需要数百至数千个例子来归纳归纳功能。这表明，多任务训练需要许多有效的训练对，以实现其承诺与目前的方法。要想继续扩大数据集的创建和目标的设计，达到用现有技术强行达到的程度，将是非常困难的。这激发了对执行多任务学习的额外设置的探索。

The current best performing systems on language tasks utilize a combination of pre-training and supervised finetuning. This approach has a long history with a trend towards more flexible forms of transfer. First, word vectors were learned and used as inputs to task-specific architectures (Mikolov et al., 2013) (Collobert et al., 2011), then the contextual representations of recurrent networks were transferred (Dai & Le, 2015) (Peters et al., 2018), and recent work suggests that task-specific architectures are no longer necessary and transferring many self-attention blocks is sufficient (Radford et al., 2018) (Devlin et al., 2018).

1. Mikolov, T., Sutskever, I., Chen, K., Corrado, G. S., and Dean, J. Distributed representations of words and phrases and their compositionality. In Advances in neural information processing systems, pp. 3111–3119, 2013.
2. Collobert, R., Weston, J., Bottou, L., Karlen, M., Kavukcuoglu, K., and Kuksa, P. Natural language processing (almost) from scratch. Journal of Machine Learning Research, 12(Aug):2493– 2537, 2011.
3. Dai, A. M. and Le, Q. V. Semi-supervised sequence learning. In Advances in neural information processing systems, pp. 3079– 3087, 2015.
4. Peters, M. E., Neumann, M., Iyyer, M., Gardner, M., Clark, C., Lee, K., and Zettlemoyer, L. Deep contextualized word representations. arXiv preprint arXiv:1802.05365, 2018.
5. GPT：　Radford, A., Narasimhan, K., Salimans, T., and Sutskever, I. Improving language understanding by generative pre-training.
6. BERT：Devlin, J., Chang, M.-W., Lee, K., and Toutanova, K. Bert: Pretraining of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805, 2018.

目前在语言任务方面表现最好的系统是结合了培训前的培训和监督下的微调。这一方法历史悠久，其趋势是更灵活的转让形式。首先,词作为输入向量学习和使用特定于任务的架构(Mikolov et al ., 2013) (Collobert et al ., 2011),然后网络转移复发的上下文表示(戴&勒,2015)(Peters等人,2018),和最近的研究表明,特定于任务架构不再是必要和转移许多self-attention块就足够了(雷德福et al ., 2018) (Devlin et al ., 2018)。

These methods still require supervised training in order to perform a task. When only minimal or no supervised data is available, another line of work has demonstrated the promise of language models to perform specific tasks, such as commonsense reasoning (Schwartz et al., 2017) and sentiment analysis (Radford et al., 2017).

1. Schwartz, R., Sap, M., Konstas, I., Zilles, L., Choi, Y., and Smith, N. A. Story cloze task: Uw nlp system. In Proceedings of the 2nd Workshop on Linking Models of Lexical, Sentential and Discourse-level Semantics, pp. 52–55, 2017.
2. Radford, A., Jozefowicz, R., and Sutskever, I. Learning to generate reviews and discovering sentiment. arXiv preprint arXiv:1704.01444, 2017.

为了完成一项任务，这些方法仍然需要监督训练。当只有极少的或没有监督数据可用时，另一个领域的研究表明，语言模型有望执行特定的任务，如常识推理(Schwartz et al.， 2017)和情感分析(Radford et al.， 2017)。

In this paper, we connect these two lines of work and continue the trend of more general methods of transfer. We demonstrate language models can perform down-stream tasks in a zero-shot setting – without any parameter or architecture modification. We demonstrate this approach shows potential by highlighting the ability of language models to perform a wide range of tasks in a zero-shot setting. We achieve promising, competitive, and state of the art results depending on the task.

在本文中，我们将这两种工作联系起来，并延续了更一般的转移方法的趋势。我们证明了语言模型可以在零起点设置下执行下游任务——不需要任何参数或架构修改。我们通过强调语言模型在零镜头设置下执行广泛任务的能力来展示这种方法的潜力。我们根据任务实现有希望的、有竞争力的和最先进的结果。

## 2. Approach

At the core of our approach is language modeling. Language modeling is usually framed as unsupervised distribution estimation from a set of examples $(x_1, x_2, ..., x_n)$ each composed of variable length sequences of symbols $(s_1, s_2, ..., s_n)$. Since language has a natural sequential ordering, it is common to factorize the joint probabilities over symbols as the product of conditional probabilities (Jelinek & Mercer, 1980) (Bengio et al., 2003):

$p(x)=\prod_{i=1}^n p(s_n|s_1,...,s_{n-1})$

1. Jelinek, F. and Mercer, R. L. Interpolated estimation of markov source parameters from sparse data. In Proceedings of the Workshop on Pattern Recognition in Practice, Amsterdam, The Netherlands: North-Holland, May., 1980.
2. Bengio, Y., Ducharme, R., Vincent, P., and Jauvin, C. A neural probabilistic language model. Journal of machine learning research, 3(Feb):1137–1155, 2003.

我们方法的核心是语言建模。语言建模通常从一组示例$(x_1, x_2，…$(s_1, s_2，…s_n)美元。由于语言具有自然的顺序性，通常将符号上的联合概率因式分解为条件概率的乘积(Jelinek & Mercer, 1980) (Bengio et al.， 2003):

This approach allows for tractable sampling from and estimation of p(x) as well as any conditionals of the form $p(s_{n-k}, ..., s_n | s_1, ..., s_{n-k-1})$. In recent years, there have been significant improvements in the expressiveness of models that can compute these conditional probabilities, such as self-attention architectures like the Transformer (Vaswani
et al., 2017).

1. Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, Ł., and Polosukhin, I. Attention is all you need. In Advances in Neural Information Processing Systems, pp. 5998–6008, 2017.

这种方法允许对p(x)进行可处理的抽样和估计，以及$p(s_{n-k}, ..., s_n | s_1, ..., s_{n-k-1})$。近年来，可以计算这些条件概率的模型的表达性有了显著的改进，例如Transformer这样的自我关注架构(Vaswani et al.， 2017)。

Learning to perform a single task can be expressed in a probabilistic framework as estimating a conditional distribution $p(output|input)$. Since a general system should be able to perform many different tasks, even for the same input, it should condition not only on the input but also on the task to be performed. That is, it should model $p(output| input,task)$. This has been variously formalized in multitask and meta-learning settings. Task conditioning is often implemented at an architectural level, such as the task specific encoders and decoders in (Kaiser et al., 2017) or at an algorithmic level such as the inner and outer loop optimization framework of MAML (Finn et al., 2017). But as exemplified in McCann et al. (2018), language provides a flexible way to specify tasks, inputs, and outputs all as a sequence of symbols. For example, a translation training example can be written as the sequence (translate to french, english text, french text). Likewise, a reading comprehension training example can be written as (answer the question, document, question, answer). McCann et al. (2018) demonstrated it was possible to train a single model, the MQAN, to infer and perform many different tasks on examples with this type of format.

1. Kaiser, L., Gomez, A. N., Shazeer, N., Vaswani, A., Parmar, N., Jones, L., and Uszkoreit, J. One model to learn them all. arXiv preprint arXiv:1706.05137, 2017.
2. Finn, C., Abbeel, P., and Levine, S. Model-agnostic metalearning for fast adaptation of deep networks. arXiv preprint arXiv:1703.03400, 2017.
3. McCann, B., Keskar, N. S., Xiong, C., and Socher, R. The natural language decathlon: Multitask learning as question answering. arXiv preprint arXiv:1806.08730, 2018.

学习执行单个任务可以在概率框架中表示为估计条件分布$p(输出|输入)$。由于一个通用系统应该能够执行许多不同的任务，即使对于相同的输入，它不仅应该对输入设置条件，还应该对要执行的任务设置条件。也就是说，它应该建模$p(输出|输入，任务)$。这在多任务和元学习环境中得到了不同程度的形式化。任务调节通常在架构级实现，例如任务特定的编码器和解码器(Kaiser et al.， 2017)，或者在算法级实现，例如MAML的内环和外环优化框架(Finn et al.， 2017)。但如McCann等人(2018)所示，语言提供了一种灵活的方式来指定任务、输入和输出，所有这些都是作为符号序列。例如，可以将翻译训练示例编写为序列(翻译成法语、英语文本、法语文本)。同样，一个阅读理解训练的例子可以写成(回答问题、文档、问题、答案)。McCann等人(2018)证明，可以训练单一模型MQAN，以这种格式在示例上推断和执行许多不同的任务。

Language modeling is also able to, in principle, learn the tasks of McCann et al. (2018) without the need for explicit supervision of which symbols are the outputs to be predicted. Since the supervised objective is the the same as the unsupervised objective but only evaluated on a subset of the sequence, the global minimum of the unsupervised objective is also the global minimum of the supervised objective. In this slightly toy setting, the concerns with density estimation as a principled training objective discussed in (Sutskever et al., 2015) are side stepped. The problem instead becomes whether we are able to, in practice, optimize the unsupervised
objective to convergence. Preliminary experiments confirmed that sufficiently large language models are able to perform multitask learning in this toy-ish setup but learning is much slower than in explicitly supervised approaches.

1. Sutskever, I., Jozefowicz, R., Gregor, K., Rezende, D., Lillicrap, T., and Vinyals, O. Towards principled unsupervised learning. arXiv preprint arXiv:1511.06440, 2015.

原则上，语言建模也能够学习McCann等人(2018)的任务，而不需要明确地监督哪些符号是要预测的输出。由于监督目标与无监督目标相同，但仅在序列的一个子集上求值，因此无监督目标的全局最小值也是有监督目标的全局最小值。在这个稍微有些玩具的设置中，(Sutskever et al.， 2015)中讨论的将密度估计作为原则性训练目标的关注点被搁置一边。相反，问题变成了我们能否在实践中优化无监督目标以使其收敛。初步实验证实，足够大的语言模型能够在这种玩具式的设置中执行多任务学习，但学习速度比显式监督方法慢得多。

While it is a large step from the well-posed setup described above to the messiness of “language in the wild”, Weston (2016) argues, in the context of dialog, for the need to develop systems capable of learning from natural language directly and demonstrated a proof of concept – learning a QA task without a reward signal by using forward prediction of a teacher’s outputs. While dialog is an attractive approach, we worry it is overly restrictive. The internet contains a vast amount of information that is passively available without the need for interactive communication. Our speculation is
that a language model with sufficient capacity will begin to learn to infer and perform the tasks demonstrated in natural language sequences in order to better predict them, regardless of their method of procurement. If a language model is able to do this it will be, in effect, performing unsupervised multitask learning. We test whether this is the case by analyzing the performance of language models in a zero-shot setting on a wide variety of tasks.

1. Weston, J. E. Dialog-based language learning. In Advances in Neural Information Processing Systems, pp. 829–837, 2016.

虽然是一个大的步骤的适定的设置上面描述的混乱在野外“语言”,韦斯顿(2016)认为,在对话框中,需要开发系统能够直接从自然语言的学习,并演示了一个概念验证,学习一个QA任务没有奖励的信号通过使用向前预测老师的输出。虽然对话是一种有吸引力的方法，但我们担心它过于严格。互联网包含了大量的信息，人们可以被动地获取这些信息，而不需要进行互动交流。我们推测，一个具有足够能力的语言模型将开始学习推断和执行自然语言序列中所演示的任务，以便更好地预测它们，而不管它们的获取方法如何。如果一个语言模型能够做到这一点，那么它实际上就是在执行无监督的多任务学习。我们通过分析语言模型在各种任务上的零距离设置的性能来测试是否存在这种情况。

## 2.1. Training Dataset

Most prior work trained language models on a single domain of text, such as news articles (Jozefowicz et al., 2016), Wikipedia (Merity et al., 2016), or fiction books (Kiros et al., 2015). Our approach motivates building as large and diverse a dataset as possible in order to collect natural language demonstrations of tasks in as varied of domains and contexts as possible.

之前的大多数工作都是在单一文本领域训练语言模型，如新闻文章(Jozefowicz等人，2016)、维基百科(Merity等人，2016)或小说书籍(Kiros等人，2015)。我们的方法鼓励构建尽可能大和多样化的数据集，以收集在尽可能多的领域和环境中任务的自然语言演示。

A promising source of diverse and nearly unlimited text is web scrapes such as Common Crawl. While these archives are many orders of magnitude larger than current language modeling datasets, they have significant data quality issues. Trinh & Le (2018) used Common Crawl in their work on commonsense reasoning but noted a large amount of documents “whose content are mostly unintelligible”. We observed similar data issues in our initial experiments with Common Crawl. Trinh & Le (2018)’s best results were achieved using a small subsample of Common Crawl which included only documents most similar to their target dataset, the Winograd Schema Challenge. While this is a pragmatic approach to improve performance on a specific task, we
want to avoid making assumptions about the tasks to be performed ahead of time.

一个有前途的来源，多样化和几乎无限的文本是网页刮擦，如常见的爬行。虽然这些归档文件比当前的语言建模数据集要大很多个数量级，但它们存在严重的数据质量问题。Trinh & Le(2018)在他们关于常识推理的工作中使用了普通的爬行，但是注意到大量的文档“其内容大多是难以理解的”。我们在最初的普通爬行实验中观察到类似的数据问题。Trinh和Le(2018)的最佳结果是通过使用一个小的常见爬行子样本实现的，该子样本只包含与目标数据集最相似的文档，即Winograd模式挑战。虽然这是一种提高特定任务性能的实用方法，但我们希望避免对将要提前执行的任务做出假设。

Instead, we created a new web scrape which emphasizes document quality. To do this we only scraped web pages which have been curated/filtered by humans. Manually filtering a full web scrape would be exceptionally expensive so as a starting point, we scraped all outbound links from Reddit, a social media platform, which received at least 3 karma. This can be thought of as a heuristic indicator for whether other users found the link interesting, educational, or just funny.

相反，我们创建了一个新的web刮，强调文档质量。为了做到这一点，我们只抓取那些由人类管理/过滤的网页。手动过滤一个完整的网页抓取会非常昂贵，所以作为一个起点，我们从社交媒体平台Reddit上抓取所有的出站链接，这个平台至少收到了3个karma。这可以被看作是其他用户是否觉得链接有趣、有教育意义或仅仅是有趣的启发式指示器。

The resulting dataset, WebText, contains the text subset of these 45 million links. To extract the text from HTML responses we use a combination of the Dragnet (Peters & Lecocq, 2013) and Newspaper1 content extractors. All results presented in this paper use a preliminary version of WebText which does not include links created after Dec 2017 and which after de-duplication and some heuristic based cleaning contains slightly over 8 million documents for a total of 40 GB of text. We removed all Wikipedia
documents from WebText since it is a common data source for other datasets and could complicate analysis due to over-lapping training data with test evaluation tasks.

得到的数据集WebText包含这4500万个链接的文本子集。为了从HTML响应中提取文本，我们结合使用了Dragnet (Peters & Lecocq, 2013)和Newspaper1内容提取器。本文中的所有结果都使用了WebText的初步版本，该版本不包括在2017年12月之后创建的链接，在重复删除和基于启发式清理之后，包含了总计40gb文本的800多万个文档。我们从WebText中删除了所有的Wikipedia文档，因为它是其他数据集的公共数据源，并且可能由于训练数据与测试评估任务重叠而使分析变得复杂。

## 2.2. Input Representation

A general language model (LM) should be able to compute the probability of (and also generate) any string. Current large scale LMs include pre-processing steps such as lowercasing, tokenization, and out-of-vocabulary tokens which restrict the space of model-able strings. While processing Unicode strings as a sequence of UTF-8 bytes elegantly fulfills this requirement as exemplified in work such as Gillick et al. (2015), current byte-level LMs are not competitive with word-level LMs on large scale datasets such as the One Billion Word Benchmark (Al-Rfou et al., 2018). We observed a similar performance gap in our own attempts to
train standard byte-level LMs on WebText.

通用语言模型(LM)应该能够计算(并生成)任何字符串的概率。当前的大型LMs包括预处理步骤，如小写、标记化和词汇表外标记，这些步骤限制了可建模字符串的空间。虽然将Unicode字符串处理为UTF-8字节序列很好地满足了这一要求，如Gillick等人(2015)的工作就证明了这一点，但当前的字节级LMs在大规模数据集(如十亿字基准测试)上无法与字级LMs竞争(al - rfou等人，2018)。我们在自己尝试在WebText上训练标准字节级LMs时也观察到了类似的性能差距。

Byte Pair Encoding (BPE) (Sennrich et al., 2015) is a practical middle ground between character and word level language modeling which effectively interpolates between word level inputs for frequent symbol sequences and character level inputs for infrequent symbol sequences. Despite its name, reference BPE implementations often operate on Unicode code points and not byte sequences. These implementations would require including the full space of Unicode symbols in order to model all Unicode strings. This would result in a base vocabulary of over 130,000 before any multi-symbol tokens are added. This is prohibitively large compared to the 32,000 to 64,000 token vocabularies often used with BPE. In contrast, a byte-level version of BPE only requires a base vocabulary of size 256. However, directly applying BPE to the byte sequence results in suboptimal merges due to BPE using a greedy frequency based heuristic for building the token vocabulary. We observed BPE including many versions of common words like dog since they occur in many variations such as dog. dog! dog? . This results in a sub-optimal allocation of limited vocabulary slots and model capacity. To avoid this, we prevent BPE from merging across character categories for any byte sequence. We add an exception for spaces which significantly improves the compression efficiency while adding only minimal fragmentation of words across multiple vocab tokens.

字节对编码(Byte Pair Encoding, BPE) (Sennrich et al.， 2015)是一种介于字符级和字级之间的实用中间地带的语言建模方法，它可以有效地插值频繁符号序列的字级输入和不频繁符号序列的字符级输入。尽管名为BPE，但引用BPE实现通常操作Unicode代码点，而不是字节序列。这些实现需要包含Unicode符号的完整空间，以便对所有Unicode字符串建模。这将导致在添加任何多符号标记之前基词汇表超过130,000。与通常与BPE一起使用的32,000到64,000个令牌词汇表相比，这实在是太大了。相比之下，字节级版本的BPE只需要256个基本词汇表。然而，直接将BPE应用于字节序列会导致次优合并，因为BPE使用基于贪婪频率的启发式方法来构建令牌词汇表。我们观察到BPE中包含了很多像dog这样的常用词，因为它们出现在很多变体中，比如dog。狗!狗吗?.这导致有限的词汇槽和模型容量的次优分配。为了避免这种情况，我们防止BPE跨字符类别合并任何字节序列。我们为空格添加了一个异常，它显著地提高了压缩效率，同时跨多个vocab标记只添加了最小的单词碎片。

This input representation allows us to combine the empirical benefits of word-level LMs with the generality of byte-level approaches. Since our approach can assign a probability to any Unicode string, this allows us to evaluate our LMs on any dataset regardless of pre-processing, tokenization, or vocab size.

这种输入表示允许我们将字级LMs的经验优势与字节级方法的通用性结合起来。由于我们的方法可以为任何Unicode字符串赋值一个概率，这允许我们在任何数据集上计算LMs，而不管预处理、记号化或vocab的大小。

### 2.3. Model

We use a Transformer (Vaswani et al., 2017) based architecture for our LMs. The model largely follows the details of the OpenAI GPT model (Radford et al., 2018) with a few modifications. Layer normalization (Ba et al., 2016)
was moved to the input of each sub-block, similar to a pre-activation residual network (He et al., 2016) and an additional layer normalization was added after the final selfattention block. A modified initialization which accounts for the accumulation on the residual path with model depth
is used. We scale the weights of residual layers at initialization
by a factor of $1/\sqrt{N}$ where N is the number of residual layers. The vocabulary is expanded to 50,257. We also increase the context size from 512 to 1024 tokens and a larger batchsize of 512 is used.

## 3. Experiments

We trained and benchmarked four LMs with approximately log-uniformly spaced sizes. The architectures are summarized in Table 2. The smallest model is equivalent to the original GPT, and the second smallest equivalent to the
largest model from BERT (Devlin et al., 2018). Our largest model, which we call GPT-2, has over an order of magnitude more parameters than GPT. The learning rate of each model was manually tuned for the best perplexity on a 5% held-out sample of WebText. All models still underfit Web-Text and held-out perplexity has as of yet improved given more training time.

我们对四个LMs进行了训练和基准测试，它们的大小大约是log均匀间隔的。架构总结在表2中。最小的模型相当于原始的GPT，第二小的模型相当于BERT (Devlin et al.， 2018)的最大模型。我们最大的模型，我们称之为GPT-2，它的参数比GPT多一个数量级。每个模型的学习率都是在5%的WebText样本上手动调整以获得最佳的perplexity。所有的模型仍然不适合网络文本和helout perplexity已经改善了给更多的训练时间。

### 3.1. Language Modeling

As an initial step towards zero-shot task transfer, we are interested in understanding how WebText LM’s perform at zero-shot domain transfer on the primary task they are trained for – language modeling. Since our model operates on a byte level and does not require lossy pre-processing
or tokenization, we can evaluate it on any language model benchmark. Results on language modeling datasets are commonly reported in a quantity which is a scaled or exponentiated version of the average negative log probability per canonical prediction unit - usually a character, a byte, or
a word. We evaluate the same quantity by computing the log-probability of a dataset according to a WebText LM and dividing by the number of canonical units. For many of these datasets, WebText LMs would be tested significantly outof- distribution, having to predict aggressively standardized text, tokenization artifacts such as disconnected punctuation
and contractions, shuffled sentences, and even the string <UNK> which is extremely rare in WebText - occurring only 26 times in 40 billion bytes. We report our main results in Table 3 using invertible de-tokenizers which remove as many of these tokenization / pre-processing artifacts as possible. Since these de-tokenizers are invertible, we can still calculate the log probability of a dataset and they can be thought of as a simple form of domain adaptation. We observe gains of 2.5 to 5 perplexity for GPT-2 with these de-tokenizers.

作为迈向零镜头任务转移的第一步，我们有兴趣了解WebText LM如何在零镜头域转移的主要任务上执行他们被训练为非语言建模。由于我们的模型在字节级别上运行，不需要有损预处理或标记化，所以我们可以在任何语言模型基准上对其进行评估。语言建模数据集的结果通常以每规范预测单元(通常是一个字符、一个字节或一个单词)的平均负对数概率的比例或指数形式来报告。我们通过根据WebText LM计算数据集的日志概率，并除以规范单元的数量来评估相同的数量。对于许多这样的数据集，WebText LMs将被测试出显著的out - distribution，必须预测积极标准化的文本，标记化工件，如断开的标点和缩写，打乱的句子，甚至字符串，这在WebText中极为罕见，在400亿字节中仅出现26次。我们在表3中报告了使用可逆反令牌器的主要结果，该反令牌器删除了尽可能多的这些令牌化/预处理工件。由于这些解记号器是可逆的，我们仍然可以计算数据集的日志概率，它们可以被认为是一种简单的域适应形式。我们观察到使用这些解令器GPT-2获得2.5到5个perplexity。

WebText LMs transfer well across domains and datasets, improving the state of the art on 7 out of the 8 datasets in a zero-shot setting. Large improvements are noticed on small datasets such as Penn Treebank and WikiText-2 which have only 1 to 2 million training tokens. Large improvements are also noticed on datasets created to measure long-term
dependencies like LAMBADA (Paperno et al., 2016) and the Children’s Book Test (Hill et al., 2015). Our model is still significantly worse than prior work on the One Billion Word Benchmark (Chelba et al., 2013). This is likely due to a combination of it being both the largest dataset and having some of the most destructive pre-processing - 1BW’s sentence level shuffling removes all long-range structure.

WebText LMs可以很好地跨域和数据集传输，在一个零镜头设置中改进8个数据集中的7个数据集的状态。在小型的数据集中，如Penn Treebank和WikiText-2，只有100万到200万的训练令牌，可以看到很大的改进。在为测量长期依赖关系而创建的数据集(如LAMBADA (Paperno et al.， 2016)和儿童书籍测试(Hill et al.， 2015)上也发现了巨大的改进。我们的模型仍然比之前在十亿词基准上的工作要差很多(Chelba et al.， 2013)。这可能是由于它既是最大的数据集，又有一些最具破坏性的预处理——1BW的句子层次变换删除了所有的长程结构。

### 3.2. Children’s Book Test

The Children’s Book Test (CBT) (Hill et al., 2015) was created to examine the performance of LMs on different categories of words: named entities, nouns, verbs, and prepositions. Rather than reporting perplexity as an evaluation metric, CBT reports accuracy on an automatically constructed cloze test where the task is to predict which of 10 possible choices for an omitted word is correct. Following the LM approach introduced in the original paper, we compute the probability of each choice and the rest of the sentence conditioned on this choice according to the LM, and predict the one with the highest probability. As seen in Figure 2 performance steadily improves as model size is increased and closes the majority of the gap to human performance on this test. Data overlap analysis showed one of the CBT test set books, The Jungle Book by Rudyard Kipling, is in WebText, so we report results on the validation set which has no significant overlap. GPT-2 achieves new state of the art results of 93.3% on common nouns and 89.1% on named entities. A de-tokenizer was applied to remove PTB style tokenization artifacts from CBT.

儿童书籍测试(CBT) (Hill et al.， 2015)是为了检查LMs在不同类别的单词上的表现:命名实体、名词、动词和介词。CBT并没有将复杂程度作为一个评估指标，而是在一个自动构建的完形填空测试中报告准确性，该测试的任务是预测一个遗漏的单词在10个选项中哪个选项是正确的。按照原文介绍的LM方法，我们根据LM计算出每个选择的概率以及以此为条件的句子其余部分，并预测出概率最高的一个。如图2所示，随着模型大小的增加，性能稳步提高，并消除了在此测试中与人类性能的大部分差距。数据重叠分析显示，其中一个CBT测试集集，鲁德亚德·吉卜林的《奇幻森林》，是在WebText中，所以我们报告的验证集的结果没有明显的重叠。GPT-2在常见名词上获得了93.3%的最新成果，在命名实体上获得了89.1%的最新成果。在CBT中应用去标记器去除PTB风格的标记伪影。

### 3.3. LAMBADA

The LAMBADA dataset (Paperno et al., 2016) tests the ability of systems to model long-range dependencies in text. The task is to predict the final word of sentences which require at least 50 tokens of context for a human to successfully predict. GPT-2 improves the state of the art from 99.8 (Grave et al., 2016) to 8.6 perplexity and increases the accuracy of LMs on this test from 19% (Dehghani et al., 2018) to 52.66%. Investigating GPT-2’s errors showed most predictions are valid continuations of the sentence, but are not valid final words. This suggests that the LM is not using the additional useful constraint that the word must be the final of the sentence. Adding a stop-word filter as an approximation to this further increases accuracy to 63.24%, improving the overall state of the art on this task by 4%. The previous state of the art (Hoang et al., 2018) used a different restricted prediction setting where the outputs of the model were constrained to only words that appeared in the context. For GPT-2, this restriction is harmful rather than helpful since 19% of answers are not in context. We use a version of the dataset without preprocessing.

LAMBADA数据集(Paperno et al.， 2016)测试了系统在文本中建模长期依赖关系的能力。任务是预测句子的最后一个单词，这些句子需要至少50个上下文标记才能成功预测。GPT-2将该技术的状态从99.8 (Grave et al.， 2016)提高到8.6 perplexity，并将LMs在该测试中的准确性从19% (Dehghani et al.， 2018)提高到52.66%。研究GPT-2的错误表明，大多数预测都是句子的有效延续，而不是有效的结束词。这表明LM没有使用附加的有用约束，即单词必须是句子的结尾。在此基础上添加一个停止字过滤器，可以进一步将准确度提高到63.24%，从而将该任务的整体水平提高4%。之前的技术状态(Hoang et al.， 2018)使用了一种不同的限制性预测设置，其中模型的输出仅限于上下文中出现的单词。对于GPT-2，这个限制是有害的，而不是有益的，因为19%的答案没有上下文。我们使用不经过预处理的数据集版本。

### 3.4.Winograd Schema Challenge

The Winograd Schema challenge (Levesque et al., 2012) was constructed to measure the capability of a system to perform commonsense reasoning by measuring its ability to resolve ambiguities in text. Recently Trinh & Le (2018) demonstrated significant progress on this challenge using LMs, by predicting the resolution of the ambiguity with higher probability. We follow their problem formulation and visualize the performance of our models with both full and partial scoring techniques in Figure 3. GPT-2 improves state of the art accuracy by 7%, achieving 70.70%. The dataset is quite small with only 273 examples so we recommend reading Trichelair et al. (2018) to help contextualize this result.

Winograd模式挑战(Levesque et al.， 2012)通过测量系统解决文本中歧义的能力来测量系统执行常识推理的能力。最近，Trinh和Le(2018)通过预测具有更高概率的歧义的解决方案，证明了使用LMs在这一挑战上取得的重大进展。我们遵循它们的问题公式，并使用图3中的完整和部分评分技术可视化我们的模型的性能。GPT-2将最先进的精度提高了7%，达到70.70%。数据集非常小，只有273个例子，所以我们建议阅读Trichelair等人(2018)的文章，以帮助了解这个结果的背景。

### 3.5. Reading Comprehension

The Conversation Question Answering dataset (CoQA) Reddy et al. (2018) consists of documents from 7 different domains paired with natural language dialogues between a question asker and a question answerer about the document. CoQA tests reading comprehension capabilities and also the ability of models to answer questions that depend on conversation history (such as “Why?”).

对话问题回答数据集(CoQA) Reddy等人(2018)由来自7个不同领域的文档组成，文档中问题提问者和问题回答者之间的自然语言对话。CoQA测试阅读理解能力和模型回答依赖于会话历史的问题的能力(比如“为什么?”)。

Greedy decoding from GPT-2 when conditioned on a document, the history of the associated conversation, and a final token A: achieves 55 F1 on the development set. This matches or exceeds the performance of 3 out of 4 baseline systems without using the 127,000+ manually collected question answer pairs those baselines were trained on. The supervised SOTA, a BERT based system (Devlin et al., 2018), is nearing the 89 F1 performance of humans. While GPT-2’s performance is exciting for a system without any supervised training, some inspection of its answers and errors suggests GPT-2 often uses simple retrieval based heuristics such as answer with a name from the document in response to a who question.

贪婪的解码时从GPT-2条件文档,相关的历史对话,和最后一个标记:达到55 F1发展集。这个比赛或超过3的4基线系统的性能不使用127000 +手动收集问题回答对这些基线被训练。监督SOTA是一个基于BERT的系统(Devlin et al.， 2018)，接近人类的89个F1性能。虽然GPT-2的性能对于一个没有任何监督培训的系统来说是令人兴奋的，但是对其答案和错误的一些检查表明，GPT-2通常使用简单的基于启发式的检索方法，例如使用文档中的名称来回答who问题。

### 3.6. Summarization

We test GPT-2’s ability to perform summarization on the CNN and Daily Mail dataset (Nallapati et al., 2016). To induce summarization behavior we add the text TL;DR: after the article and generate 100 tokens with Top-k random sampling (Fan et al., 2018) with k = 2 which reduces repetition and encourages more abstractive summaries than greedy decoding. We use the first 3 generated sentences in these 100 tokens as the summary. While qualitatively the generations resemble summaries, as shown in Table 14, they often focus on recent content from the article or confuse specific details such as how many cars were involved in a crash or whether a logo was on a hat or shirt. On the commonly reported ROUGE 1,2,L metrics the generated summaries only begin to approach the performance of classic neural baselines and just barely outperforms selecting 3 random sentences from the article. GPT-2’s performance drops by 6.4 points on the aggregate metric when the task hint is removed which demonstrates the ability to invoke task specific behavior in a language model with natural language.

我们测试了GPT-2在CNN和每日邮报数据集上执行摘要的能力(Nallapati et al.， 2016)。为了诱导摘要行为，我们在文章之后添加文本TL;DR:，并使用Top-k随机抽样(Fan et al.， 2018)生成100个令牌(k = 2)，这减少了重复，并鼓励了比贪婪解码更抽象的摘要。我们使用这100个标记中的前3个生成的句子作为摘要。虽然这几代人在质量上类似于总结，如表14所示，但他们往往只关注文章中最近的内容，或混淆具体细节，如车祸涉及多少辆汽车，或帽子或衬衫上是否有标识。在通常报告的ROUGE 1、2、L指标上，生成的摘要仅仅开始接近经典的神经基线的性能，仅仅比从文章中随机选择3个句子的性能好一点。当删除任务提示时，GPT-2的性能在聚合度量上下降6.4点，这表明可以使用自然语言在语言模型中调用特定于任务的行为。

### 3.7. Translation

We test whether GPT-2 has begun to learn how to translate from one language to another. In order to help it infer that this is the desired task, we condition the language model on a context of example pairs of the format english sentence = french sentence and then after a final prompt of english sentence = we sample from the model with greedy decoding and use the first generated sentence as the translation. On the WMT-14 English-French test set, GPT-2 gets 5 BLEU, which is slightly worse than a word-by-word substitution with a bilingual lexicon inferred in previous work on unsupervised word translation (Conneau et al., 2017b). On the WMT-14 French-English test set, GPT-2 is able to leverage its very strong English language model to perform significantly better, achieving 11.5 BLEU. This outperforms several unsupervised machine translation baselines from (Artetxe et al., 2017) and (Lample et al., 2017) but is still much worse than the 33.5 BLEU of the current best unsupervised machine translation approach (Artetxe et al., 2019). Performance on this task was surprising to us, since we deliberately removed non-English webpages from WebText as a filtering step. In order to confirm this, we ran a byte-level language detector2 onWebText which detected only 10MB of data in the French language which is approximately 500x smaller than the monolingual French corpus common in prior unsupervised machine translation research.

我们测试GPT-2是否已经开始学习如何从一种语言翻译成另一种语言。为了帮助推断这是所需的任务,我们条件对上下文的语言模型示例对英语句子=法语句子的格式之后最后一个提示我们样本模型的英文句子=贪婪的解码和使用生成第一个句子的翻译。在WMT-14英法测试集上，GPT-2获得5个BLEU，这比之前关于无监督单词翻译的工作中使用双语词典推断的逐字替换略差(Conneau et al.， 2017b)。在WMT-14法语-英语测试集上，GPT-2能够利用其强大的英语语言模型来显著提高性能，实现11.5 BLEU。这比来自(Artetxe et al.， 2017)和(Lample et al.， 2017)的几个无监督机器翻译基线要好得多，但仍然比当前最好的无监督机器翻译方法的33.5 BLEU差得多(Artetxe et al.， 2019)。这个任务的性能让我们惊讶，因为我们故意从WebText中删除非英语网页作为过滤步骤。为了证实这一点，我们在webtext上运行了一个字节级的语言检测器2，它只检测到法语语言中的10MB数据，这比之前无监督机器翻译研究中常见的单语法语语料库大约小500倍。

### 3.8. Question Answering

A potential way to test what information is contained within a language model is to evaluate how often it generates the correct answer to factoid-style questions. Previous showcasing of this behavior in neural systems where all information is stored in parameters such as A Neural Conversational Model (Vinyals & Le, 2015) reported qualitative results due to the lack of high-quality evaluation datasets. The recently introduced Natural Questions dataset (Kwiatkowski et al., 2019) is a promising resource to test this more quantitatively. Similar to translation, the context of the language model is seeded with example question answer pairs which helps the model infer the short answer style of the dataset. GPT-2 answers 4.1% of questions correctly when evaluated by the exact match metric commonly used on reading comprehension datasets like SQUAD.3 As a comparison point, the smallest model does not exceed the 1.0% accuracy of an incredibly simple baseline which returns the most common answer for each question type (who, what, where, etc...). GPT-2 answers 5.3 times more questions correctly, suggesting that model capacity has been a major factor in the poor performance of neural systems on this kind of task as of yet. The probability GPT-2 assigns to its generated answers is well calibrated and GPT-2 has an accuracy of 63.1% on the 1% of questions it is most confident in. The 30 most confident answers generated by GPT-2 on development set questions are shown in Table 5. The performance of GPT-2 is still much, much, worse than the 30 to 50% range of open domain question answering systems which hybridize information retrieval with extractive document question answering (Alberti et al., 2019).

测试语言模型中包含哪些信息的一种潜在方法是评估它生成真实问题的正确答案的频率。由于缺乏高质量的评价数据集，以前在神经系统中，所有信息都存储在参数中，如神经会话模型(Vinyals & Le, 2015)，对这种行为的展示报告了定性结果。最近引入的自然问题数据集(Kwiatkowski等人，2019年)是一个有前景的资源，可以更定量地测试这一点。与翻译类似，语言模型的上下文被播种了示例问题-答案对，这有助于模型推断数据集的简短回答风格。GPT-2回答问题正确评估时的4.1%精确匹配度量常用SQUAD.3等阅读理解数据集作为比较点,最小的模型不超过1.0%的准确率的一个非常简单的基线回报最常见的回答每个问题类型(何人,何事,何地,等等…)。GPT-2答对的问题是其他问题的5.3倍，这表明模型容量是目前神经系统在这类任务中表现不佳的一个主要因素。对于生成的答案，GPT-2分配的概率得到了很好的校准，GPT-2对其最自信的1%的问题的准确率为63.1%。由GPT-2生成的关于开发集问题的30个最自信的答案如表5所示。GPT-2的性能仍然比30 - 50%范围的开放域问答系统差得多，开放域问答系统将信息检索与提取文档问答相结合(Alberti et al.， 2019)。

## 4. Generalization vs Memorization

Recent work in computer vision has shown that common image datasets contain a non-trivial amount of near-duplicate images. For instance CIFAR-10 has 3.3% overlap between train and test images (Barz & Denzler, 2019). This results in an over-reporting of the generalization performance of machine learning systems. As the size of datasets increases this issue becomes increasingly likely which suggests a similar phenomena could be happening with WebText. Therefore it is important to analyze how much test data also shows up in the training data.

最近在计算机视觉领域的研究表明，常见的图像数据集包含大量的近重复图像。例如CIFAR-10在列车和测试图像之间有3.3%的重叠(Barz & Denzler, 2019)。这导致了对机器学习系统泛化性能的过度报告。随着数据集的大小增加，这个问题变得越来越可能，这表明类似的现象可能发生在WebText。因此，重要的是分析有多少测试数据也显示在训练数据中。

To study this we created Bloom filters containing 8-grams of WebText training set tokens. To improve recall, strings were normalized to contain only lower-cased alphanumeric words with a single space as a delimiter. The Bloom filters were constructed such that the false positive rate is upper bounded by 1 108 . We further verified the low false positive rate by generating 1M strings, of which zero were found by the filter.

为了研究这个问题，我们创建了包含8克WebText训练集标记的Bloom过滤器。为了提高回忆能力，字符串被规范化为只包含大小写字母数字单词和一个空格作为分隔符。布隆滤波器的构造使得假阳性率的上界为1 108。我们通过生成1M字符串进一步验证了低假阳性率，过滤器发现其中零。

These Bloom filters let us calculate, given a dataset, the percentage of 8-grams from that dataset that are also found in the WebText training set. Table 6 shows this overlap analysis for the test sets of common LM benchmarks. Common LM datasets’ test sets have between 1-6% overlap withWeb- Text train, with an average of overlap of 3.2%. Somewhat surprisingly, many datasets have larger overlaps with their own training splits, with an average of 5.9% overlap.

这些Bloom过滤器让我们计算，给定一个数据集，在WebText训练集中也可以找到该数据集的8克的百分比。表6显示了公共LM基准测试集的重叠分析。普通LM数据集的测试集与web - Text训练有1-6%的重叠，平均重叠率为3.2%。有些令人惊讶的是，许多数据集与它们自己的训练片段有较大的重叠，平均有5.9%的重叠。

Our approach optimizes for recall, and while manual inspection of the overlaps shows many common phrases, there are many longer matches that are due to duplicated data. This is not unique to WebText. For instance, we discovered that the test set of WikiText-103 has an article which is also in the training dataset. Since there are only 60 articles in the test set there is at least an overlap of 1.6%.4 Potentially more worryingly, 1BW has an overlap of nearly 13.2% with its own training set according to our procedure.

我们的方法优化了收回，虽然手动检查重叠部分会显示许多常见的短语，但是由于重复的数据，会有许多较长的匹配。这并不是WebText独有的。例如，我们发现WikiText-103的测试集有一篇文章也在训练数据集中。由于测试集中只有60篇文章，所以至少有1.6%的重叠。可能更令人担忧的是，根据我们的程序，1BW与它自己的训练集有将近13.2%的重叠。

For the Winograd Schema Challenge, we found only 10 schemata which had any 8-gram overlaps with the WebText training set. Of these, 2 were spurious matches. Of the remaining 8, only 1 schema appeared in any contexts that gave away the answer.

在Winograd模式挑战中，我们发现只有10个模式与WebText训练集有任何8克的重叠。在剩下的8个模式中，只有一个模式出现在给出答案的任何上下文中。

For CoQA, about 15% of documents in the news domain are already in WebText and the model performs about 3 F1 better on these. CoQA’s development set metric reports the average performance over 5 different domains and we measure a gain of about 0.5-1.0 F1 due to overlap across the various domains. However, no actual training questions or answers are in WebText since CoQA was released after the cutoff date for links in WebText.

对于CoQA，新闻域中约15%的文档已经在WebText中，模型在这些方面的性能大约好3个一级。CoQA的开发集度量报告了5个不同领域的平均性能，我们测量了由于不同领域的重叠而产生的大约0.5-1.0 F1的增益。然而，由于CoQA是在WebText链接截止日期之后发布的，所以在WebText中没有实际的培训问题或答案。

On LAMBADA, the average overlap is 1.2%. GPT-2 performs about 2 perplexity better on examples with greater than 15% overlap. Recalculating metrics when excluding all examples with any overlap shifts results from 8.6 to 8.7 perplexity and reduces accuracy from 63.2% to 62.9%. This very small change in overall results is likely due to only 1 in 200 examples having significant overlap.

在LAMBADA，平均重叠率是1.2%。对于重叠大于15%的例子，GPT-2的perplexity表现更好，约为2个perplexity。当排除所有有重叠的示例时，重新计算矩阵将结果从8.6转移到8.7 perplexity，并将准确性从63.2%降低到62.9%。总体结果的这个非常小的变化可能是由于只有1 / 200的例子有明显的重叠。

Overall, our analysis suggests that data overlap between WebText training data and specific evaluation datasets provides a small but consistent benefit to reported results. However, for most datasets we do not notice significantly larger overlaps than those already existing between standard training and test sets, as Table 6 highlights.

总的来说，我们的分析表明WebText训练数据和特定评估数据集之间的数据重叠为报告的结果提供了一个小但一致的好处。然而，对于大多数数据集，我们并没有注意到比标准训练集和测试集之间已经存在的大量重叠，如表6所示。

Understanding and quantifying how highly similar text impacts performance is an important research question. Better de-duplication techniques such as scalable fuzzy matching could also help better answer these questions. For now, we recommend the use of n-gram overlap based de-duplication as an important verification step and sanity check during the creation of training and test splits for new NLP datasets.

理解和量化相似文本对性能的影响是一个重要的研究问题。更好的去重复技术，如可伸缩模糊匹配，也可以帮助更好地回答这些问题。现在，我们建议在为新的NLP数据集创建训练和测试分割时，使用基于n克重叠的重复数据删除作为一个重要的验证步骤和完整性检查。

Another potential way of determining whether the performance of WebText LMs is attributable to memorization is inspecting their performance on their own held-out set. As shown in Figure 4, performance on both the training and test sets of WebText are similar and improve together as model size is increased. This suggests even GPT-2 is still underfitting on WebText in many ways.

另一种判断WebText LMs的性能是否归因于记忆的潜在方法是检查它们在各自的输出集上的性能。如图4所示，随着模型大小的增加，WebText的训练集和测试集的性能都是相似的，并一起提高。这表明即使是GPT-2在很多方面仍然不适合WebText。

GPT-2 is also able to write news articles about the discovery of talking unicorns. An example is provided in Table 13.

GPT-2还能够撰写关于发现会说话的独角兽的新闻文章。表13提供了一个示例。

## 5. Related Work

A significant portion of this work measured the performance of larger language models trained on larger datasets. This is similar to the work of Jozefowicz et al. (2016) which scaled RNN based language models on the 1 Billion Word Benchmark. Bajgar et al. (2016) also previously improved results on the Children’s Book Test by creating a much larger training dataset out of Project Gutenberg to supplement the standard training dataset. Hestness et al. (2017) conducted a thorough analysis of how the performance of various deep learning models changes as a function of both model capacity and dataset size. Our experiments, while much noisier across tasks, suggest similar trends hold for sub-tasks of an objective and continue into the 1B+ parameter regime.

这项工作的一个重要部分是测量在更大的数据集上训练的更大的语言模型的性能。这与Jozefowicz等人(2016)在10亿个单词的基准上缩放基于RNN的语言模型的工作类似。Bajgar等人(2016)之前也通过从古登堡计划中创建更大的训练数据集来补充标准训练数据集，从而改进了儿童书籍测试的结果。Hestness等(2017)深入分析了各种深度学习模型的性能随模型容量和数据集大小的变化。我们的实验中，虽然任务之间的噪音更大，但表明了类似的趋势也适用于目标的子任务，并持续到1B+参数状态。

Interesting learned functionality in generative models has been documented before such as the cells in an RNN language model performing line-width tracking and quote/comment detection Karpathy et al. (2015). More inspirational to our work was the observation of Liu et al. (2018) that a model trained to generate Wikipedia articles also learned to translate names between languages.

在生成模型中有趣的功能已经被记录下来，例如RNN语言模型中的单元执行行宽跟踪和引用/评论检测Karpathy等(2015)。对我们的工作更鼓舞人心的是Liu等人(2018)的观察，他们发现一个经过训练生成维基百科文章的模型也学会了在不同语言之间翻译名称。

Previous work has explored alternative approaches to filtering and constructing a large text corpus of web pages, such as the iWeb Corpus (Davies, 2018).

之前的工作探索了过滤和构建大型网页文本语料库的替代方法，如iWeb语料库(Davies, 2018)。

There has been extensive work on pre-training methods for language tasks. In addition to those mentioned in the introduction, GloVe (Pennington et al., 2014) scaled word vector representation learning to all of Common Crawl. An influential early work on deep representation learning for text was Skip-thought Vectors (Kiros et al., 2015). McCann et al. (2017) explored the use of representations derived from machine translation models and Howard & Ruder (2018) improved the RNN based fine-tuning approaches of (Dai & Le, 2015). (Conneau et al., 2017a) studied the transfer performance of representations learned by natural language inference models and (Subramanian et al., 2018) explored large-scale multitask training.

在语言任务的训练前方法方面有大量的工作。除了引言中提到的那些，GloVe (Pennington et al.， 2014)将单词向量表示学习扩展到所有常见的爬行。一项关于文本深度表征学习的有影响力的早期工作是跳跃思维向量(Kiros et al.， 2015)。McCann等(2017)探索了机器翻译模型中表示的使用，Howard & Ruder(2018)改进了基于RNN的微调方法(Dai & Le, 2015)。(Conneau et al.， 2017a)研究了自然语言推理模型学习表征的传递性能，(Subramanian et al.， 2018)探索了大规模多任务训练。

(Ramachandran et al., 2016) demonstrated that seq2seq models benefit from being initialized with pre-trained language models as encoders and decoders. More recent work has shown that LM pre-training is helpful when fine-tuned for difficult generation tasks like chit-chat dialog and dialog based question answering systems as well (Wolf et al., 2019) (Dinan et al., 2018).

(Ramachandran et al.， 2016)证明了seq2seq模型受益于使用预训练的语言模型作为编码器和解码器进行初始化。最近的研究表明，LM预训练有助于对困难的生成任务进行微调，比如聊天对话框和基于对话的问题回答系统(Wolf等，2019年)(Dinan等，2018年)。

## 6. Discussion

Much research has been dedicated to learning (Hill et al., 2016), understanding (Levy & Goldberg, 2014), and critically evaluating (Wieting & Kiela, 2019) the representations of both supervised and unsupervised pre-training methods. Our results suggest that unsupervised task learning is an additional promising area of research to explore. These findings potentially help explain the widespread success of pre-training techniques for down-stream NLP tasks as we show that, in the limit, one of these pre-training techniques begins to learn to perform tasks directly without the need for supervised adaption or modification.

许多研究致力于学习(Hill et al.， 2016)、理解(Levy & Goldberg, 2014)和批判性评估(Wieting & Kiela, 2019)监督和非监督的培训前方法。我们的研究结果表明，无监督任务学习是另一个有前途的研究领域。这些发现可能有助于解释下游NLP任务训练前技术的广泛成功，因为我们表明，在极限情况下，这些训练前技术之一开始学习直接执行任务，而不需要监督适应或修改。

On reading comprehension the performance of GPT-2 is competitive with supervised baselines in a zero-shot setting. However, on other tasks such as summarization, while it is qualitatively performing the task, its performance is still only rudimentary according to quantitative metrics. While suggestive as a research result, in terms of practical applications, the zero-shot performance of GPT-2 is still far from use-able.

在阅读理解方面，GPT-2的性能与零镜头设置下的监督基线具有竞争力。然而，在总结等其他任务上，虽然它定性地执行任务，但根据定量度量，它的性能仍然是非常初级的。研究结果表明，在实际应用方面，GPT-2的零炮点性能还远远不能使用。

We have studied the zero-shot performance of WebText LMs on many canonical NLP tasks, but there are many additional tasks that could be evaluated. There are undoubtedly many practical tasks where the performance of GPT-2 is still no better than random. Even on common tasks that we evaluated on, such as question answering and translation, language models only begin to outperform trivial baselines when they have sufficient capacity.

我们已经研究了WebText LMs在许多规范NLP任务上的零突发性能，但是还有许多额外的任务需要评估。毫无疑问，在许多实际任务中，GPT-2的性能仍然不如random。即使是在我们评估的常见任务上，比如回答问题和翻译，语言模型只有在它们有足够的能力时才会开始超越普通的基线。

While zero-shot performance establishes a baseline of the potential performance of GPT-2 on many tasks, it is not clear where the ceiling is with finetuning. On some tasks, GPT-2’s fully abstractive output is a significant departure from the extractive pointer network (Vinyals et al., 2015) based outputs which are currently state of the art on many question answering and reading comprehension datasets. Given the prior success of fine-tuning GPT, we plan to investigate fine-tuning on benchmarks such as decaNLP and GLUE, especially since it is unclear whether the additional training data and capacity of GPT-2 is sufficient to overcome the inefficiencies of uni-directional representations demonstrated by BERT (Devlin et al., 2018).

虽然zero-shot性能为GPT-2在许多任务上的潜在性能建立了一个基线，但是不清楚微调的上限在哪里。在一些任务中，GPT-2的完全抽象输出与基于提取指针网络(Vinyals et al.， 2015)的输出有很大的不同，后者目前处于许多问题回答和阅读理解数据集的最先进水平。鉴于之前微调GPT的成功,我们计划调查微调等基准decaNLP和胶水,特别是目前尚不清楚GPT-2的额外的训练数据和能力足以克服单向的低效率表征证明了伯特(Devlin et al ., 2018)。

## 7. Conclusion

When a large language model is trained on a sufficiently large and diverse dataset it is able to perform well across many domains and datasets. GPT-2 zero-shots to state of the art performance on 7 out of 8 tested language modeling datasets. The diversity of tasks the model is able to perform in a zero-shot setting suggests that high-capacity models trained to maximize the likelihood of a sufficiently varied text corpus begin to learn how to perform a surprising amount of tasks without the need for explicit supervision.

当一个大型语言模型在一个足够大和多样化的数据集上训练时，它能够在许多领域和数据集上执行良好。GPT-2零镜头状态的艺术表现的8个测试的语言建模数据集中的7个。该模型能够在零镜头设置下执行的任务的多样性表明，经过训练以最大化足够多样化的文本语料库的可能性的高容量模型开始学习如何在不需要明确监督的情况下执行数量惊人的任务。
